{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6f25846",
   "metadata": {},
   "source": [
    "# Dataset Report: Custom Dataset\n",
    "\n",
    "Here is an example of how to run the [DatasetReport](https://satishlokkoju.github.io/deepview/api/deepview/introspectors.html#deepview.introspectors.DatasetReport) on the dataset. This notebook will demonstrate how to build the data for the report using DeepView. An example of how to visualize the report output with the Canvas UI framework (Coming Soon !)\n",
    "\n",
    "For a deeper understanding of the Dataset Report, please see the [doc page](https://satishlokkoju.github.io/deepview/introspectors/data_introspection/dataset_report.html).\n",
    "\n",
    "Before proceeding, please review the \"How to Use\" section in the docs, starting with the [How to Load A Model](https://satishlokkoju.github.io/deepview/how_to/connect_model.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bd89e3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset Report: (1) Setup\n",
    "\n",
    "Here, group together required imports and set desired paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d7245d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger(\"numba\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7771bbdc-7c16-417b-8cd5-dad4c22bda36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from watermark import watermark\n",
    "print(watermark(packages=\"deepview,deepview_tensorflow,deepview_data,canvas_ux,canvas_summary,canvas_list,canvas_scatterplot,canvas_duplicates,canvas_familiarity\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d54847",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# This notebook pieces together a pipeline to run a dataset through a model, with pre- and post- processing,\n",
    "#    and then feeds it into the Dataset Report for full analysis\n",
    "from deepview.introspectors import DatasetReport, ReportConfig\n",
    "from deepview.base import Batch, Producer, pipeline, ImageFormat\n",
    "from deepview.processors import Cacher, FieldRenamer, ImageResizer, Pooler, Processor\n",
    "from deepview_tensorflow import load_tf_model_from_path\n",
    "\n",
    "# For future protection, any deprecated DeepView features will be treated as errors\n",
    "from deepview.exceptions import enable_deprecation_warnings\n",
    "enable_deprecation_warnings()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b32ffcd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Dataset Report: (1) Setup - Download Model\n",
    "\n",
    "Download a [MobileNet](https://keras.io/api/applications/mobilenet/) model from keras that has been pre-trained on the ImageNet dataset, which is similar to the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset used. [TFModelExamples](https://satishlokkoju.github.io/deepview/api/deepview_tensorflow/index.html#deepview_tensorflow.TFModelExamples) are used to load MobileNet, but any model can be loaded, as described [here](https://satishlokkoju.github.io/deepview/how_to/connect_model.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ad8231",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from deepview_tensorflow import TFModelExamples\n",
    "\n",
    "mobilenet = TFModelExamples.MobileNet()\n",
    "mobilenet_preprocessor = mobilenet.preprocessing\n",
    "assert mobilenet_preprocessor is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7286abe",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset Report: (2) DeepView Producer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ebd4f7-738d-4934-aa79-7026a34e117c",
   "metadata": {},
   "source": [
    "To use the Kaggle API, you need to:\n",
    "\n",
    "* Create a Kaggle account if you haven't already\n",
    "* Generate an API token\n",
    "* Download the kaggle.json file\n",
    "* Place the file in the correct directory\n",
    "\n",
    "Here are the step-by-step instructions:\n",
    "\n",
    "1. Go to your Kaggle account settings: https://www.kaggle.com/account\n",
    "2. Scroll down to the \"API\" section\n",
    "3. Click on \"Create New API Token\"\n",
    "4. This will download a kaggle.json file\n",
    "5. Now, you need to place this file in the correct location. The error message suggests the path should be  ~/.kaggle/kaggle.json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a36af7d-000f-4bf6-9bbf-db44a9841dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "def download_kaggle_dataset(dataset_id: str, output_dir: str = \"data\") -> None:\n",
    "    \"\"\"\n",
    "    Download a dataset from Kaggle.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset_id : str\n",
    "        Kaggle dataset identifier (e.g., 'username/dataset-name')\n",
    "    output_dir : str, optional\n",
    "        Directory where the dataset should be downloaded (default: 'data')\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Initialize the Kaggle API\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    \n",
    "    # Download the dataset\n",
    "    print(f\"Downloading dataset {dataset_id} to {output_dir}...\")\n",
    "    api.dataset_download_files(\n",
    "        dataset_id,\n",
    "        path=output_dir,\n",
    "        unzip=True\n",
    "    )\n",
    "    print(\"Download complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7486bd8-a1fd-47c8-9c52-077859074bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_kaggle_dataset(dataset_id=\"agrigorev/clothing-dataset-full\", output_dir=\"data/clothing-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b365d0e5-72b3-4501-a322-1ae409a90e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def organize_images(dataset_dir, output_dir):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(os.path.join(dataset_dir, 'images.csv'))\n",
    "    # Create the base output directory if it doesn't exist\n",
    "    base_output_dir = os.path.join(dataset_dir, output_dir)\n",
    "    os.makedirs(base_output_dir, exist_ok=True)\n",
    "    source_dir = os.path.join(dataset_dir, 'images_original')\n",
    "    # Get unique labels\n",
    "    unique_labels = df['label'].unique()\n",
    "\n",
    "    # Create subdirectories for each label\n",
    "    for label in unique_labels:\n",
    "        label_dir = os.path.join(base_output_dir, label)\n",
    "        os.makedirs(label_dir, exist_ok=True)\n",
    "\n",
    "    # Move files to their respective directories\n",
    "    for index, row in df.iterrows():\n",
    "        image_filename = f\"{row['image']}.jpg\"\n",
    "        source_path = os.path.join(source_dir, image_filename)\n",
    "        destination_path = os.path.join(base_output_dir, row['label'], image_filename)\n",
    "\n",
    "        try:\n",
    "            if os.path.exists(source_path):\n",
    "                shutil.copy2(source_path, destination_path)\n",
    "            else:\n",
    "                print(f\"Warning: Source file not found: {source_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error copying {image_filename}: {str(e)}\")\n",
    "\n",
    "    print(\"\\nOrganization complete!\")\n",
    "    print(f\"Images have been organized into subfolders in the '{base_output_dir}' directory\")\n",
    "    return base_output_dir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31b7f5b-b427-48c4-9909-51c8689eefce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = organize_images(\"./data/clothing-dataset\", 'images_by_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe9f1ef-5ff5-4833-ade2-94ada630b6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Example directory structure:\n",
    "    root_folder/\n",
    "        class1/\n",
    "            image1.jpg\n",
    "            image2.jpg\n",
    "        class2/\n",
    "            image3.jpg\n",
    "            image4.jpg\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb4c9f8-6611-4fa1-acef-8fd2a1cd716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepview_data import CustomDatasets\n",
    "dataset_producer = CustomDatasets.ImageFolderDataset(root_folder=dataset_path,image_size=(224, 224), max_samples=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cb47b0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset Report: (3) Model Inference w/ Pre + Post Processing\n",
    "\n",
    "First load the saved TF Keras model into deepview using [load_tf_model_from_path](https://satishlokkoju.github.io/deepview/api/tensorflow/index.html#deepview_tensorflow.load_tf_model_from_path).\n",
    "\n",
    "Then, apply pre and post processing steps around model inference. This consists of the following steps:\n",
    "\n",
    "- mobilenet preprocessing: Keras has its own preprocessing for MobileNet, this function is turned into a DeepView [Processor](https://satishlokkoju.github.io/deepview/api/deepview/processors.html#deepview.processors.Processor) so it can be chained together with other pre / post processing stages\n",
    "- resize images to fit the input of MobileNet, (224, 224) using an [ImageResizer](https://satishlokkoju.github.io/deepview/api/deepview/processors.html#deepview.processors.ImageResizer)\n",
    "- rename the data, which have been stored under \"images\", to match the input layer of MobileNet. To learn about how to read input and output layers from a loaded deepview model, please read through the [Dataset Errors and Rare Samples example notebook](familiarity_for_rare_data_discovery.ipynb).\n",
    "- run inference and extract intermediate embeddings (this time, just `conv_pw_13`, other layers can be added, e.g. what is found when inspecting them from the `deepview_model`. Again, please see the [Dataset Errors and Rare Samples example notebook](familiarity_for_rare_data_discovery.ipynb) for more of a guide on this piece.\n",
    "- max pool the responses before DeepView processing using a DeepView [Pooler](https://satishlokkoju.github.io/deepview/api/deepview/processors.html#deepview.processors.Pooler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e56ac5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Chain together all operations around running the data through the model\n",
    "model_stages = (\n",
    "    mobilenet_preprocessor,\n",
    "    \n",
    "    ImageResizer(pixel_format=ImageFormat.HWC, size=(224, 224)),\n",
    "    \n",
    "    # Run inference with MobileNet and extract intermediate embeddings\n",
    "    # (this time, just `conv_pw_130`, but other layers can be added)\n",
    "    # :: Note: This auto-detects the input layer and connects up 'images' to it:\n",
    "    mobilenet.model(requested_responses=['conv_pw_13']),\n",
    "    \n",
    "    Pooler(dim=(1, 2), method=Pooler.Method.MAX)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83213dc6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset Report: (4) Chain together pipeline stages\n",
    "\n",
    "Create the DeepView [pipeline](https://satishlokkoju.github.io/deepview/api/deepview/base.html#deepview.base.pipeline) from the base CIFAR-10 Producer that was written earlier, and then by unwrapping the tuple of model-related [PipelineStages](https://satishlokkoju.github.io/deepview/api/deepview/base.html#deepview.base.PipelineStage) defined in the prior cell.\n",
    "\n",
    "No processing is done at this point, but will be called when the Dataset Report \"introspects\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93cec27",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finally put it all together!\n",
    "producer = pipeline(\n",
    "    # Original data producer that will yield batches\n",
    "    dataset_producer,\n",
    "\n",
    "    # unwrap the tuple of pipeline stages that contain model inference, and pre/post-processing\n",
    "    *model_stages,\n",
    "\n",
    "    # Cache responses to play around with data in future cells\n",
    "    Cacher()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc83dd1a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset Report: (5) Run Dataset Report. Introspect!\n",
    "\n",
    "All compute is performed in this step by pulling batches through the entire pipeline.\n",
    "\n",
    "[DatasetReport](https://betterwidhdata.github.io/deepview/api/deepview/introspectors.html#deepview.DatasetReport) [introspect](https://betterwidhdata.github.io/deepview/api/deepview/introspectors.html#deepview.introspectors.DatasetReport.introspect) takes the data through the pipeline and gives us a report object. This object contains `data`, which is a pandas dataframe table with metadata about each data sample like familiarity, duplicates, overall summary, and projection that can be passed to Canvas for visualization.\n",
    "\n",
    "A [ReportConfig](https://betterwidhdata.github.io/deepview/api/deepview/introspectors.html#deepview.introspectors.ReportConfig) is passed as input in the next cell that specifies that to not run the projection or familiarity components. This is simply for speed of this example notebook. To run all components, simply omit the config parameter from the `DatasetReport.introspect` function.\n",
    "\n",
    "Displayed in the next cell are the first five rows of the resulting `report.data` that is interpretable by the Canvas UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acfd945",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# The most time consuming, since all compute is done here\n",
    "# Data passed through DeepView in batches to produce the backend data table that will be displayed by Canvas\n",
    "\n",
    "custom_config = ReportConfig(\n",
    "    projection=None,\n",
    "    duplicates=None\n",
    ")\n",
    "\n",
    "\n",
    "report = DatasetReport.introspect(\n",
    "    producer,\n",
    "    #config=custom_config # unComment this out to run with custom config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea30e5d-c902-4300-80e5-78a435c32022",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "report.data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a109302",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset Report: (6) Visualization\n",
    "\n",
    "To visualize the results, the resulting ``report`` can be fed into the Canvas UI framework. To save ``report`` to disk, run:\n",
    "\n",
    "```\n",
    "report.to_disk('./report_files/')\n",
    "```\n",
    "where ``./report_files`` can be any path. This Pandas DataFrame can then be loaded and fed into Canvas UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b20466",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "report.to_disk('./report_files_clothes/', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7939811-66b5-47ac-93cc-0ca947dbb939",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Canvas in Jupyter Notebooks\n",
    "\n",
    "Let's use Canvas to explore this dataset in a Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c64938-3202-466d-9f6a-ac7000af4dab",
   "metadata": {},
   "source": [
    "To use Canvas, we'll import the main library and instantiate a Canvas object, passing the pandas DataFrame analysis and a file path to the dataset we downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1f2dff",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import canvas_ux\n",
    "\n",
    "canva = canvas_ux.Canvas(report.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c442513-dcb6-472e-8f3c-107e6e66cdd0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To use the different Canvas widgets, you can import them indepdently. Let's first look at the Summary widget to see the overall distributions of our datset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eebc6a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from canvas_summary import CanvasSummary\n",
    "\n",
    "canva.widget(CanvasSummary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfe04fa-38fa-4f17-972f-6218ad9b8fd9",
   "metadata": {},
   "source": [
    "Instead of a summary, if we want to browse through the data we can use the List widget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cc1ce2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from canvas_list import CanvasList\n",
    "\n",
    "canva.widget(CanvasList)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11e972f-5d59-4414-acb1-20f39ef61690",
   "metadata": {},
   "source": [
    "It's common to use dimensionality reduction techniques to summarize and find patterns in ML dataset. DeepView already ran a reduction, and saves it when running a DataSet Report. We can use the Scatterplot widget to visualize this embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f188e4f7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from canvas_scatterplot import CanvasScatterplot\n",
    "\n",
    "canva.widget(CanvasScatterplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd90e61e-03c6-45ee-bb49-d616ec4793c6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Some datasets can contain duplicates: data instances that are the same or very similar to others. These can be hard to find, and become espeically problematic if the same data instance is in the training and testing splits. We can answer these questions using the Duplicates widget.\n",
    "\n",
    "Hint: Take a look at the `automobile` class, where there are duplicates across train and test data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99eb410",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from canvas_duplicates import CanvasDuplicates\n",
    "\n",
    "canva.widget(CanvasDuplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fead64d0-f2f2-49a5-9384-da66938ff658",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Lastly, we can use advanced ML metrics and the Familiarity widget to find the most and least representative data instances from a given datset, which can help identify model biases and annotation errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723aaa6a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from canvas_familiarity import CanvasFamiliarity\n",
    "\n",
    "canva.widget(CanvasFamiliarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c723812-ee65-461b-842d-650d157fb8a0",
   "metadata": {},
   "source": [
    "## Visualization as a Standalone Export\n",
    "\n",
    "Report can also be exported as a standalone static export to be shared with others or hosted. To explore this example in a web browser, you can export the report to local folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5461b3b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "canva.export('./canvas_report_clothes', name=\"Canvas ClothesDataset Visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd9c165-fc12-4228-85f5-98249e6bbb3c",
   "metadata": {},
   "source": [
    "You can now serve the dataset report. For example, from the `canvas_export` folder, run a simple server from the command line:\n",
    "\n",
    "```bash\n",
    "python -m http.server\n",
    "```\n",
    "\n",
    "And navigate to http://localhost:8000/."
   ]
  }
 ],
 "metadata": {
  "finalized": {
   "timestamp": 1638994625349,
   "trusted": true
  },
  "kernelspec": {
   "display_name": "deepview_dev",
   "language": "python",
   "name": "deepview_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
